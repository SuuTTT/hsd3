# Defaults for SACMT agent

name: 'sacmt'
gamma: 0.99  # discount factor
polyak: 0.995  # polyak step size for updating target network
batch_size: 100
rpbuf_size: 1e6  # replay buffer size
rpbuf_device: auto
samples_per_update: 50  # perform updates every N samples
num_updates: ${agent.samples_per_update}
warmup_samples: 1000  # use first N samples to fill replay buffer
randexp_samples: 10000  # explore with random actions for first N samples
clip_grad_norm: 0.0 # only used if > 0
update_reachability: true

alpha: 0.1  # If optim_alpha is not null, this is just the initial alpha value
per_task_alpha: true  # Use seperate alphas for different tasks
target_entropy_factor: 1.0 # If optim_alpha is not null
optim_alpha:  # Can be set to null to disable entropy coefficient learning and use target_entropy instead.
  _target_: torch.optim.Adam
  lr: 1e-4

ignore_eoe: false
